{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "impaired-communications",
   "metadata": {},
   "source": [
    "# Natural language processing: project - Model Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "blessed-reggae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "facial-documentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "CD_KEY = \"--NLP_PROJECT_MODEL_DEMO_IN_ROOT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "classified-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CD_KEY not in os.environ:\n",
    "    os.environ[CD_KEY] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "collectible-garbage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/data/projekti/faks/OPJe/project\n"
     ]
    }
   ],
   "source": [
    "if (\n",
    "    CD_KEY not in os.environ\n",
    "    or os.environ[CD_KEY] is None\n",
    "    or len(os.environ[CD_KEY]) == 0\n",
    "    or os.environ[CD_KEY] == \"false\"\n",
    "):\n",
    "    %cd ..\n",
    "else:\n",
    "    print(os.getcwd())\n",
    "    \n",
    "os.environ[CD_KEY] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-rochester",
   "metadata": {},
   "source": [
    "## Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "flying-malawi",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Callable, List\n",
    "\n",
    "\n",
    "from prado import PradoCore\n",
    "from prado.datasets import pad_projections\n",
    "from prado.datasets import ProcessedDataset\n",
    "from prado.datasets import BasicPradoTransform, BasicPradoAugmentation\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.modelling.datasets import (\n",
    "    ImdbDataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-separation",
   "metadata": {},
   "source": [
    "## Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "soviet-level",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elementwise_transformation(transformation: Callable):\n",
    "    def _f(elements: List) -> List:\n",
    "        return [transformation(x) for x in elements]\n",
    "    \n",
    "    return _f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-watershed",
   "metadata": {},
   "source": [
    "## Initialization/Restoring last checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "extra-superintendent",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "paths = {\n",
    "    \"training_dataset\": \"data/processed/ready-to-use/imdb/train.tsv\",\n",
    "}\n",
    "\n",
    "augmentation_config = {\n",
    "    \"insertion_probability\": 0.01,\n",
    "    \"deletion_probability\": 0.01,\n",
    "    \"swap_probability\": 0.01,\n",
    "}\n",
    "\n",
    "model_config = {\n",
    "    \"feature_length\": 32,\n",
    "    \"embedding_length\": 32,\n",
    "    \"dropout\": 0.2,\n",
    "    \"out_channels\": 3,\n",
    "    \"skipgram_patterns\": [\n",
    "        \"1\",\n",
    "        \"11\",\n",
    "        \"101\",\n",
    "        \"111\",\n",
    "    ],\n",
    "    \"out_features\": 2,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-mexico",
   "metadata": {},
   "source": [
    "## Setting up dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "distributed-nature",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = ImdbDataset(\n",
    "    path=paths[\"training_dataset\"],\n",
    "    delimiter=\"\\t\",\n",
    "    max_entries=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "going-guess",
   "metadata": {},
   "source": [
    "### Dataset preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "present-concord",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_prado_transform = BasicPradoTransform()\n",
    "basic_prado_augmentation = BasicPradoAugmentation(\n",
    "    insertion_probability=augmentation_config[\"insertion_probability\"],\n",
    "    deletion_probability=augmentation_config[\"deletion_probability\"],\n",
    "    swap_probability=augmentation_config[\"swap_probability\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "religious-wonder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming dataset: 100%|██████████| 10/10 [00:00<00:00, 212.37it/s]\n"
     ]
    }
   ],
   "source": [
    "training_dataset = ProcessedDataset(\n",
    "    original_dataset=training_dataset,\n",
    "    transformation_map={\n",
    "        0: basic_prado_transform\n",
    "    },\n",
    "    verbosity=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "official-visiting",
   "metadata": {},
   "source": [
    "## Setting up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "small-median",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PradoCore(\n",
    "    feature_length=model_config[\"feature_length\"],\n",
    "    embedding_length=model_config[\"embedding_length\"],\n",
    "    dropout=model_config[\"dropout\"],\n",
    "    out_channels=model_config[\"out_channels\"],\n",
    "    skipgram_patterns=model_config[\"skipgram_patterns\"],\n",
    "    out_features=model_config[\"out_features\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elect-mobile",
   "metadata": {},
   "source": [
    "## Getting some results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efficient-hebrew",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming dataset: 100%|██████████| 10/10 [00:00<00:00, 226.76it/s]\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(\n",
    "    ProcessedDataset(\n",
    "        original_dataset=training_dataset,\n",
    "        transformation_map={\n",
    "            0: get_elementwise_transformation(basic_prado_augmentation)\n",
    "        },\n",
    "        verbosity=1\n",
    "    ),\n",
    "    batch_size=2,\n",
    "    collate_fn=pad_projections\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "conceptual-sequence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2164,  0.0978],\n",
      "        [-0.2240,  0.1144]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.1725,  0.1611],\n",
      "        [-0.2170,  0.1134]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.1918,  0.1222],\n",
      "        [-0.2045,  0.1279]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.1715,  0.1608],\n",
      "        [-0.2083,  0.1099]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.2292,  0.0933],\n",
      "        [-0.1928,  0.1329]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "for tokens, labels in dataloader:\n",
    "    result = model(tokens)\n",
    "    print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-project",
   "language": "python",
   "name": "nlp-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
